{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,accuracy_score,mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/min_max_df.csv', parse_dates=['date'], index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>98146</th>\n",
       "      <th>98148</th>\n",
       "      <th>98155</th>\n",
       "      <th>98166</th>\n",
       "      <th>98168</th>\n",
       "      <th>98177</th>\n",
       "      <th>98178</th>\n",
       "      <th>98188</th>\n",
       "      <th>98198</th>\n",
       "      <th>98199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>2014-10-13</td>\n",
       "      <td>0.018880</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.061503</td>\n",
       "      <td>0.003108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>0.060352</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.167046</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>0.013382</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.030372</td>\n",
       "      <td>0.005743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>0.069011</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.120729</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>0.056678</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.099468</td>\n",
       "      <td>0.004579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id       date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520 2014-10-13  0.018880  0.222222   0.066667     0.061503   \n",
       "1  6414100192 2014-12-09  0.060352  0.222222   0.233333     0.167046   \n",
       "2  5631500400 2015-02-25  0.013382  0.111111   0.066667     0.030372   \n",
       "3  2487200875 2014-12-09  0.069011  0.333333   0.333333     0.120729   \n",
       "4  1954400510 2015-02-18  0.056678  0.222222   0.200000     0.099468   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  98146  98148  98155  98166  98168  \\\n",
       "0  0.003108     0.0         0.0   0.0  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "1  0.004072     0.4         0.0   0.0  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "2  0.005743     0.0         0.0   0.0  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "3  0.002714     0.0         0.0   0.0  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "4  0.004579     0.0         0.0   0.0  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   98177  98178  98188  98198  98199  \n",
       "0    0.0    1.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = ['sqft_living', 'yr_built', 'PctofLot', 'age', 'waterfront', 'sqft_lot',\n",
    "        'view', 'bedrooms', 'condition', 'floors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "oheNames = [98001, 98002, 98003, 98004, 98005, 98006, 98007, 98008, 98010,\n",
    "        98011, 98014, 98019, 98022, 98023, 98024, 98027, 98028, 98029,\n",
    "        98030, 98031, 98032, 98033, 98034, 98038, 98039, 98040, 98042,\n",
    "        98045, 98052, 98053, 98055, 98056, 98058, 98059, 98065, 98070,\n",
    "        98072, 98074, 98075, 98077, 98092, 98102, 98103, 98105, 98106,\n",
    "        98107, 98108, 98109, 98112, 98115, 98116, 98117, 98118, 98119,\n",
    "        98122, 98125, 98126, 98133, 98136, 98144, 98146, 98148, 98155,\n",
    "        98166, 98168, 98177, 98178, 98188, 98198, 98199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "strOheNames = [str(i) for i in oheNames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sqft_living',\n",
       " 'yr_built',\n",
       " 'PctofLot',\n",
       " 'age',\n",
       " 'waterfront',\n",
       " 'sqft_lot',\n",
       " 'view',\n",
       " 'bedrooms',\n",
       " 'condition',\n",
       " 'floors']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = new_feats + strOheNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[new_feats]\n",
    "y = df.price\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Lasso':Lasso(alpha=1.0, tol=.01), \n",
    "          'Ridge':Ridge(alpha=1.0), \n",
    "          'RandForest':RandomForestRegressor(n_jobs=-1), \n",
    "          'XGB':XGBRegressor(), \n",
    "          'LightGBM':LGBMRegressor()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso | MSE = -9.831193018383644e-05 | MAE = 0.03105367332240898\n",
      "Ridge | MSE = 0.7910002283417119 | MAE = 0.013103903760436058\n",
      "RandForest | MSE = 0.8000839696415696 | MAE = 0.011850092252051156\n",
      "XGB | MSE = 0.8315112843462551 | MAE = 0.010889055218647454\n",
      "LightGBM | MSE = 0.8165871023626173 | MAE = 0.01117594034410866\n"
     ]
    }
   ],
   "source": [
    "for key, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    score = model.score(X_test, y_test)\n",
    "    MAE = mean_absolute_error(y_test, preds)\n",
    "    print(key, '| MSE =', score, '| MAE =', MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    min_delta=0.001, \n",
    "    patience=20, \n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "kerasModel = keras.Sequential([\n",
    "    layers.Dense(32, activation='sigmoid', kernel_regularizer=regularizers.l2(1e-4), input_shape=[80,]),\n",
    "    #layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='sigmoid', kernel_regularizer=regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    #layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='sigmoid', kernel_regularizer=regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    #layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='sigmoid', kernel_regularizer=regularizers.l2(1e-4)),\n",
    "    layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "540/540 [==============================] - 2s 2ms/step - loss: 0.1568 - mean_absolute_error: 0.1224 - val_loss: 0.0680 - val_mean_absolute_error: 0.0337\n",
      "Epoch 2/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0810 - mean_absolute_error: 0.0466 - val_loss: 0.0696 - val_mean_absolute_error: 0.0352\n",
      "Epoch 3/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0751 - mean_absolute_error: 0.0407 - val_loss: 0.0719 - val_mean_absolute_error: 0.0376\n",
      "Epoch 4/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0724 - mean_absolute_error: 0.0381 - val_loss: 0.0633 - val_mean_absolute_error: 0.0290\n",
      "Epoch 5/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0713 - mean_absolute_error: 0.0369 - val_loss: 0.0648 - val_mean_absolute_error: 0.0305\n",
      "Epoch 6/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0693 - mean_absolute_error: 0.0349 - val_loss: 0.0607 - val_mean_absolute_error: 0.0263\n",
      "Epoch 7/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0685 - mean_absolute_error: 0.0342 - val_loss: 0.0692 - val_mean_absolute_error: 0.0349\n",
      "Epoch 8/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0671 - mean_absolute_error: 0.0327 - val_loss: 0.0604 - val_mean_absolute_error: 0.0261\n",
      "Epoch 9/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0669 - mean_absolute_error: 0.0325 - val_loss: 0.0588 - val_mean_absolute_error: 0.0245\n",
      "Epoch 10/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0659 - mean_absolute_error: 0.0316 - val_loss: 0.0589 - val_mean_absolute_error: 0.0246\n",
      "Epoch 11/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0649 - mean_absolute_error: 0.0307 - val_loss: 0.0565 - val_mean_absolute_error: 0.0222\n",
      "Epoch 12/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0651 - mean_absolute_error: 0.0308 - val_loss: 0.0637 - val_mean_absolute_error: 0.0294\n",
      "Epoch 13/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0650 - mean_absolute_error: 0.0307 - val_loss: 0.0613 - val_mean_absolute_error: 0.0270\n",
      "Epoch 14/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0642 - mean_absolute_error: 0.0299 - val_loss: 0.0557 - val_mean_absolute_error: 0.0214\n",
      "Epoch 15/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0640 - mean_absolute_error: 0.0297 - val_loss: 0.0582 - val_mean_absolute_error: 0.0239\n",
      "Epoch 16/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0629 - mean_absolute_error: 0.0287 - val_loss: 0.0553 - val_mean_absolute_error: 0.0211\n",
      "Epoch 17/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0636 - mean_absolute_error: 0.0294 - val_loss: 0.0604 - val_mean_absolute_error: 0.0262\n",
      "Epoch 18/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0641 - mean_absolute_error: 0.0299 - val_loss: 0.0685 - val_mean_absolute_error: 0.0342\n",
      "Epoch 19/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0642 - mean_absolute_error: 0.0300 - val_loss: 0.0565 - val_mean_absolute_error: 0.0223\n",
      "Epoch 20/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0637 - mean_absolute_error: 0.0295 - val_loss: 0.0585 - val_mean_absolute_error: 0.0243\n",
      "Epoch 21/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0630 - mean_absolute_error: 0.0287 - val_loss: 0.0540 - val_mean_absolute_error: 0.0198\n",
      "Epoch 22/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0632 - mean_absolute_error: 0.0290 - val_loss: 0.0597 - val_mean_absolute_error: 0.0255\n",
      "Epoch 23/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0623 - mean_absolute_error: 0.0281 - val_loss: 0.0627 - val_mean_absolute_error: 0.0285\n",
      "Epoch 24/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0639 - mean_absolute_error: 0.0297 - val_loss: 0.0697 - val_mean_absolute_error: 0.0355\n",
      "Epoch 25/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0629 - mean_absolute_error: 0.0288 - val_loss: 0.0584 - val_mean_absolute_error: 0.0242\n",
      "Epoch 26/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0631 - mean_absolute_error: 0.0289 - val_loss: 0.0588 - val_mean_absolute_error: 0.0246\n",
      "Epoch 27/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0625 - mean_absolute_error: 0.0284 - val_loss: 0.0666 - val_mean_absolute_error: 0.0324\n",
      "Epoch 28/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0633 - mean_absolute_error: 0.0292 - val_loss: 0.0628 - val_mean_absolute_error: 0.0286\n",
      "Epoch 29/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0632 - mean_absolute_error: 0.0291 - val_loss: 0.0724 - val_mean_absolute_error: 0.0383\n",
      "Epoch 30/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0627 - mean_absolute_error: 0.0286 - val_loss: 0.0610 - val_mean_absolute_error: 0.0269\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001)\n",
    "\n",
    "kerasModel.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mean_absolute_error',\n",
    "    metrics=['mean_absolute_error'],\n",
    ")\n",
    "\n",
    "history = kerasModel.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=32,\n",
    "    epochs=30,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_feats = ['bedrooms','bathrooms', 'sqft_living', 'sqft_lot', 'floors', \n",
    "              'waterfront', 'view', 'condition', 'grade', 'sqft_above', \n",
    "              'sqft_basement', 'yr_built', 'yr_renovated', 'sqft_living15', \n",
    "              'sqft_lot15', 'renovated', 'since_reno', 'has_basement', \n",
    "              'basement_lot_pct', 'aboveground_lot_pct', 'PctofLot']\n",
    "full_feats = full_feats + strOheNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[full_feats]\n",
    "y = df.price\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17276, 91)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    min_delta=0.001, \n",
    "    patience=20, \n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "kerasModel = keras.Sequential([\n",
    "    layers.Dense(32, activation='sigmoid', kernel_regularizer=regularizers.l2(1e-4), input_shape=[91,]),\n",
    "    #layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='sigmoid', kernel_regularizer=regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    #layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='sigmoid', kernel_regularizer=regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    #layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='sigmoid', kernel_regularizer=regularizers.l2(1e-4)),\n",
    "    layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "540/540 [==============================] - 2s 2ms/step - loss: 0.1608 - mean_absolute_error: 0.1262 - val_loss: 0.0666 - val_mean_absolute_error: 0.0320\n",
      "Epoch 2/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0770 - mean_absolute_error: 0.0424 - val_loss: 0.0662 - val_mean_absolute_error: 0.0316\n",
      "Epoch 3/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0724 - mean_absolute_error: 0.0378 - val_loss: 0.0631 - val_mean_absolute_error: 0.0285\n",
      "Epoch 4/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0699 - mean_absolute_error: 0.0354 - val_loss: 0.0613 - val_mean_absolute_error: 0.0267\n",
      "Epoch 5/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0690 - mean_absolute_error: 0.0345 - val_loss: 0.0606 - val_mean_absolute_error: 0.0261\n",
      "Epoch 6/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0679 - mean_absolute_error: 0.0333 - val_loss: 0.0634 - val_mean_absolute_error: 0.0289\n",
      "Epoch 7/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0670 - mean_absolute_error: 0.0325 - val_loss: 0.0597 - val_mean_absolute_error: 0.0252\n",
      "Epoch 8/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0665 - mean_absolute_error: 0.0320 - val_loss: 0.0581 - val_mean_absolute_error: 0.0235\n",
      "Epoch 9/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0661 - mean_absolute_error: 0.0316 - val_loss: 0.0592 - val_mean_absolute_error: 0.0247\n",
      "Epoch 10/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0665 - mean_absolute_error: 0.0320 - val_loss: 0.0581 - val_mean_absolute_error: 0.0236\n",
      "Epoch 11/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0652 - mean_absolute_error: 0.0308 - val_loss: 0.0572 - val_mean_absolute_error: 0.0227\n",
      "Epoch 12/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0654 - mean_absolute_error: 0.0309 - val_loss: 0.0576 - val_mean_absolute_error: 0.0232\n",
      "Epoch 13/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0635 - mean_absolute_error: 0.0291 - val_loss: 0.0554 - val_mean_absolute_error: 0.0209\n",
      "Epoch 14/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0639 - mean_absolute_error: 0.0295 - val_loss: 0.0645 - val_mean_absolute_error: 0.0300\n",
      "Epoch 15/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0648 - mean_absolute_error: 0.0303 - val_loss: 0.0598 - val_mean_absolute_error: 0.0254\n",
      "Epoch 16/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0634 - mean_absolute_error: 0.0290 - val_loss: 0.0676 - val_mean_absolute_error: 0.0332\n",
      "Epoch 17/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0635 - mean_absolute_error: 0.0290 - val_loss: 0.0557 - val_mean_absolute_error: 0.0212\n",
      "Epoch 18/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0634 - mean_absolute_error: 0.0290 - val_loss: 0.0579 - val_mean_absolute_error: 0.0234\n",
      "Epoch 19/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0634 - mean_absolute_error: 0.0290 - val_loss: 0.0532 - val_mean_absolute_error: 0.0188\n",
      "Epoch 20/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0629 - mean_absolute_error: 0.0285 - val_loss: 0.0564 - val_mean_absolute_error: 0.0220\n",
      "Epoch 21/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0638 - mean_absolute_error: 0.0294 - val_loss: 0.0525 - val_mean_absolute_error: 0.0182\n",
      "Epoch 22/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0630 - mean_absolute_error: 0.0287 - val_loss: 0.0607 - val_mean_absolute_error: 0.0263\n",
      "Epoch 23/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0629 - mean_absolute_error: 0.0286 - val_loss: 0.0570 - val_mean_absolute_error: 0.0226\n",
      "Epoch 24/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0626 - mean_absolute_error: 0.0283 - val_loss: 0.0528 - val_mean_absolute_error: 0.0184\n",
      "Epoch 25/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0634 - mean_absolute_error: 0.0291 - val_loss: 0.0613 - val_mean_absolute_error: 0.0270\n",
      "Epoch 26/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0633 - mean_absolute_error: 0.0290 - val_loss: 0.0547 - val_mean_absolute_error: 0.0204\n",
      "Epoch 27/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0634 - mean_absolute_error: 0.0290 - val_loss: 0.0554 - val_mean_absolute_error: 0.0210\n",
      "Epoch 28/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0645 - mean_absolute_error: 0.0302 - val_loss: 0.0548 - val_mean_absolute_error: 0.0205\n",
      "Epoch 29/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0623 - mean_absolute_error: 0.0280 - val_loss: 0.0513 - val_mean_absolute_error: 0.0170\n",
      "Epoch 30/30\n",
      "540/540 [==============================] - 1s 2ms/step - loss: 0.0640 - mean_absolute_error: 0.0297 - val_loss: 0.0625 - val_mean_absolute_error: 0.0282\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001)\n",
    "\n",
    "kerasModel.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mean_absolute_error',\n",
    "    metrics=['mean_absolute_error'],\n",
    ")\n",
    "\n",
    "history = kerasModel.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=32,\n",
    "    epochs=30,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So far, XGB is our best bet. Let's do another sheet of only TF models and see if we can't get closer to MAE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
